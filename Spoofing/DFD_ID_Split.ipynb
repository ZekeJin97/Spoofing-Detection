{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-09T16:53:21.690344Z",
     "start_time": "2025-06-09T16:53:21.310447Z"
    }
   },
   "source": [
    "import os, shutil, re, random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def extract_id(filename):\n",
    "    \"\"\"Extract person ID from the filename prefix like 01__something\"\"\"\n",
    "    match = re.match(r\"(\\d+)\", filename)\n",
    "    return match.group(1) if match else \"unknown\"\n",
    "\n",
    "def collect_by_id(folder):\n",
    "    \"\"\"Group files by person ID\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for path in glob(os.path.join(folder, \"*.jpg\")):\n",
    "        fname = os.path.basename(path)\n",
    "        pid = extract_id(fname)\n",
    "        groups[pid].append(path)\n",
    "    return groups\n",
    "\n",
    "def select_samples(groups, max_total=1000, frames_per_id=8):\n",
    "    \"\"\"Select a limited number of samples per ID with randomness\"\"\"\n",
    "    all_ids = list(groups.keys())\n",
    "    random.shuffle(all_ids)\n",
    "\n",
    "    selected = []\n",
    "    for pid in all_ids:\n",
    "        if len(selected) >= max_total:\n",
    "            break\n",
    "        frames = groups[pid][:]\n",
    "        random.shuffle(frames)  # ðŸ”€ Shuffle frame list\n",
    "        selected.extend(frames[:frames_per_id])\n",
    "    return selected[:max_total]\n",
    "\n",
    "\n",
    "def split_by_id(real_dir, fake_dir, out_dir, max_samples=1000, frames_per_id=3, test_ratio=0.2):\n",
    "    real_groups = collect_by_id(real_dir)\n",
    "    fake_groups = collect_by_id(fake_dir)\n",
    "\n",
    "    # Use only overlapping IDs to simulate deepfake scenario\n",
    "    common_ids = set(real_groups.keys()).intersection(fake_groups.keys())\n",
    "    real_groups = {k: real_groups[k] for k in common_ids}\n",
    "    fake_groups = {k: fake_groups[k] for k in common_ids}\n",
    "\n",
    "    ids = list(common_ids)\n",
    "    random.shuffle(ids)\n",
    "    n_test = int(len(ids) * test_ratio)\n",
    "    train_ids, test_ids = ids[n_test:], ids[:n_test]\n",
    "\n",
    "    def copy_files(files, dest):\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "        for f in files:\n",
    "            shutil.copy2(f, os.path.join(dest, os.path.basename(f)))\n",
    "\n",
    "    def gather(groups, id_set):\n",
    "        return select_samples({k: v for k, v in groups.items() if k in id_set},\n",
    "                              max_total=max_samples, frames_per_id=frames_per_id)\n",
    "\n",
    "    # Select samples\n",
    "    train_real = gather(real_groups, train_ids)\n",
    "    train_fake = gather(fake_groups, train_ids)\n",
    "    test_real = gather(real_groups, test_ids)\n",
    "    test_fake = gather(fake_groups, test_ids)\n",
    "\n",
    "    print(f\"âœ… Train: {len(train_real)} real + {len(train_fake)} fake\")\n",
    "    print(f\"âœ… Test:  {len(test_real)} real + {len(test_fake)} fake\")\n",
    "\n",
    "    # Save\n",
    "    copy_files(train_real, os.path.join(out_dir, \"train\", \"real\"))\n",
    "    copy_files(train_fake, os.path.join(out_dir, \"train\", \"fake_generated\"))\n",
    "    copy_files(test_real, os.path.join(out_dir, \"test\", \"real\"))\n",
    "    copy_files(test_fake, os.path.join(out_dir, \"test\", \"fake_generated\"))\n",
    "\n",
    "    print(f\"âœ… Dataset saved to {out_dir}\")\n",
    "\n",
    "# Run it\n",
    "split_by_id(\n",
    "    real_dir=\"dataset/dfd_real\",\n",
    "    fake_dir=\"dataset/dfd_fake\",\n",
    "    out_dir=\"balanced_dataset_dfd\",\n",
    "    max_samples=1000,\n",
    "    frames_per_id=8,\n",
    "    test_ratio=0.2\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train: 184 real + 184 fake\n",
      "âœ… Test:  40 real + 40 fake\n",
      "âœ… Dataset saved to balanced_dataset_dfd\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
